# ğŸ›’ Challenge Data Engineer E-Commerce - Artefact CI

> Pipeline d'ingestion et modÃ©lisation de donnÃ©es de ventes e-commerce avec orchestration Airflow

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)
[![Airflow](https://img.shields.io/badge/Airflow-3.x-red.svg)](https://airflow.apache.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-336791.svg)](https://www.postgresql.org/)

---

## ğŸ“‹ Table des matiÃ¨res

- [Contexte du projet](#-contexte-du-projet)
- [Architecture technique](#-architecture-technique)
- [ModÃ©lisation des donnÃ©es](#-modÃ©lisation-des-donnÃ©es)
- [Installation et dÃ©marrage](#-installation-et-dÃ©marrage)
- [Utilisation](#-utilisation)
- [Tests](#-tests)
- [Choix techniques et justifications](#-choix-techniques-et-justifications)
- [Structure du projet](#-structure-du-projet)
- [Documentation](#-documentation)

---

## ğŸ¯ Contexte du projet

Ce projet s'inscrit dans le cadre du **challenge technique Artefact CI** pour le poste de **Stagiaire Data Engineer**. Il vise Ã  dÃ©montrer mes compÃ©tences en ingÃ©nierie de donnÃ©es sur l'ensemble de la chaÃ®ne de valeur : de l'analyse exploratoire Ã  l'orchestration de pipelines en production.

### Objectifs du challenge

âœ… **Analyser** un jeu de donnÃ©es rÃ©el de ventes e-commerce  
âœ… **ModÃ©liser** en 3Ã¨me Forme Normale (3FN) puis Domain-Key Normal Form (DKNF)  
âœ… **ImplÃ©menter** le modÃ¨le dans PostgreSQL avec contraintes et index  
âœ… **DÃ©ployer** l'infrastructure complÃ¨te via Docker Compose  
âœ… **DÃ©velopper** un script d'ingestion Python robuste et idempotent  
âœ… **Orchestrer** le pipeline avec Apache Airflow 3.x  

### PÃ©rimÃ¨tre fonctionnel

**Source de donnÃ©es** : `sales.csv` (ventes e-commerce)  
**PÃ©riode d'ingestion** : DonnÃ©es filtrÃ©es par date (`sale_date`)  
**Stockage** : MinIO (S3-compatible) â†’ PostgreSQL (OLTP & OLAP)  
**FrÃ©quence** : Ingestion quotidienne orchestrÃ©e par Airflow  

---

## ğŸ—ï¸ Architecture technique

### Stack technologique complÃ¨te

| Composant | Technologie | Version | RÃ´le |
|-----------|-------------|---------|------|
| **Orchestration** | Apache Airflow | 3.x | Planification et monitoring des pipelines |
| **Base OLTP/OLAP** | PostgreSQL | 15-alpine | Stockage normalisÃ© (DKNF) + vues analytiques |
| **Object Storage** | MinIO | latest | Stockage des fichiers sources (API S3) |
| **Conteneurisation** | Docker Compose | v2 | DÃ©ploiement multi-services |
| **ETL** | Python | 3.12 | Logique d'ingestion avec logging |
| **Tests** | Pytest | 7.4+ | Validation unitaire et d'intÃ©gration |

### Diagramme d'architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COUCHE STOCKAGE                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚     MinIO      â”‚                 â”‚   PostgreSQL     â”‚    â”‚
â”‚  â”‚  (S3-like)     â”‚                 â”‚                  â”‚    â”‚
â”‚  â”‚                â”‚                 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚ ğŸ“ Bucket:     â”‚                 â”‚  â”‚ DKNF Tablesâ”‚  â”‚    â”‚
â”‚  â”‚ folder-source  â”‚                 â”‚  â”‚  (OLTP)    â”‚  â”‚    â”‚
â”‚  â”‚                â”‚                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚ ğŸ“„ sales.csv   â”‚                 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚                â”‚                 â”‚  â”‚ Star Views â”‚  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  â”‚  (OLAP)    â”‚  â”‚    â”‚
â”‚           â”‚                         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
            â”‚                                  â–²               â”‚
            â”‚                                  â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚              COUCHE ORCHESTRATION (Airflow 3.x)         â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  DAG: ingestion_ventes_quotidien                 â”‚   â”‚   â”‚
â”‚  â”‚  â€¢ Schedule: 0 2 * * * (Quotidien Ã  2h00 UTC)   â”‚   â”‚   â”‚
â”‚  â”‚  â€¢ Connexions: AIRFLOW_CONN_POSTGRES_ECOMMERCE   â”‚   â”‚   â”‚
â”‚  â”‚               AIRFLOW_CONN_MINIO_S3              â”‚   â”‚   â”‚
â”‚  â”‚  â€¢ Variables: AIRFLOW_VAR_MINIO_BUCKET          â”‚   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚                     â”‚                                    â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚         TaskFlow API (@task decorator)           â”‚   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                      â”‚                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚              COUCHE TRAITEMENT (Python)                â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  Module: ingestion/                              â”‚  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Extraction  â”‚â†’ â”‚  Validation  â”‚             â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (MinIO)     â”‚  â”‚  (Format)    â”‚             â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚  â”‚   â”‚
â”‚  â”‚                            â–¼                      â”‚  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Transform   â”‚â†’ â”‚     Load     â”‚             â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (Pandas)    â”‚  â”‚ (PostgreSQL) â”‚             â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚  â”‚   â”‚
â”‚  â”‚                                                   â”‚  â”‚   â”‚
â”‚  â”‚  Features:                                        â”‚  â”‚   â”‚
â”‚  â”‚  â€¢ Idempotence (upsert sur clÃ©s primaires)      â”‚  â”‚   â”‚
â”‚  â”‚  â€¢ Logging dÃ©taillÃ© (INFO/ERROR)                â”‚  â”‚   â”‚
â”‚  â”‚  â€¢ Gestion d'erreurs (try/except)               â”‚  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š ModÃ©lisation des donnÃ©es

### DÃ©marche de normalisation

Le projet implÃ©mente **deux niveaux de normalisation complÃ©mentaires** conformÃ©ment aux exigences du challenge. Le raisonnement complet est documentÃ© dans [`docs/data_modeling.md`](docs/data_modeling.md).

---

## 4. ModÃ¨le Conceptuel des DonnÃ©es (MCD)

Le ModÃ¨le Conceptuel des DonnÃ©es (MCD) reprÃ©sente une **photographie brute des entitÃ©s identifiÃ©es** lors de l'analyse exploratoire, **avant toute application des rÃ¨gles de normalisation**.

Ã€ ce stade :
- âœ… Toutes les entitÃ©s mÃ©tier sont identifiÃ©es par regroupement logique
- âœ… Tous les attributs du fichier source sont conservÃ©s (y compris ceux qui seront Ã©liminÃ©s en 3FN)
- âœ… Les relations entre entitÃ©s sont Ã©tablies selon les dÃ©pendances fonctionnelles observÃ©es
- âŒ Aucune rÃ¨gle de normalisation (1FN, 2FN, 3FN) n'est encore appliquÃ©e

### 4.1 EntitÃ©s identifiÃ©es (prÃ©-normalisation)

| EntitÃ© | ClÃ© primaire | RÃ´le mÃ©tier | Justification |
|--------|-------------|-------------|---------------|
| `customers` | `customer_id` | RÃ©fÃ©rentiel clients | Attributs stables, indÃ©pendants des transactions |
| `products` | `product_id` | Catalogue produits | CaractÃ©ristiques produit hors contexte de vente |
| `channels` | `channel_id` | Canaux de distribution | Valeurs catÃ©gorielles rÃ©pÃ©tÃ©es (Online, Store...) |
| `campaigns` | `campaign_id` | Campagnes marketing | EntitÃ© optionnelle, partagÃ©e par plusieurs ventes |
| `sales` | `sale_id` | Transactions globales | Regroupe mÃ©tadonnÃ©es de vente (date, client, canal, **total_amount**) |
| `sale_items` | `item_id` | Lignes de vente | **GranularitÃ© transactionnelle** (produit + quantitÃ© + **item_total**) |

**âš ï¸ Note importante** : Les attributs `total_amount`, `item_total`, `discount_applied`, etc. sont **conservÃ©s dans le MCD** car ils reflÃ¨tent fidÃ¨lement le fichier source. Ils seront **Ã©liminÃ©s lors de la normalisation 3FN** (voir section suivante).

### 4.2 Diagramme conceptuel (prÃ©-normalisation)

![Diagramme conceptuel des donnÃ©es](data_model/logical_data_model.png)

**LÃ©gende** :
- ğŸŸ¦ **Bleu** : EntitÃ©s transactionnelles (`sales`, `sale_items`)
- ğŸŸ© **Vert** : RÃ©fÃ©rentiels mÃ©tier (`customers`, `products`, `channels`, `campaigns`)

### 4.3 CardinalitÃ©s observÃ©es

- **customers (1,1) â†” sales (0,N)** : Un client peut effectuer plusieurs ventes
- **sales (1,1) â†” sale_items (1,N)** : Une vente contient au moins une ligne
- **products (1,1) â†” sale_items (0,N)** : Un produit peut Ãªtre vendu 0 Ã  N fois
- **channels (1,1) â†” sales (1,N)** : Chaque vente a un seul canal
- **campaigns (0,1) â†” sales (0,N)** : Une vente peut Ãªtre liÃ©e ou non Ã  une campagne

---

### 5. Normalisation en TroisiÃ¨me Forme Normale (3FN)

#### 5.1 Objectif de la 3FN

**Transition depuis le MCD** : Ã€ partir du modÃ¨le conceptuel brut identifiÃ© prÃ©cÃ©demment, la normalisation 3FN vise Ã  :

- âœ… Ã‰liminer les attributs **dÃ©rivÃ©s ou calculables**
- âœ… Supprimer les **redondances**
- âœ… Garantir que chaque attribut non-clÃ© dÃ©pend **uniquement** de la clÃ© primaire
- âœ… Ã‰liminer toutes les **dÃ©pendances transitives**

#### 5.2 Attributs Ã©liminÃ©s (dÃ©rivÃ©s ou redondants)

| Attribut | Raison de l'Ã©limination | Calcul alternatif |
|----------|-------------------------|-------------------|
| `item_total` | DÃ©rivÃ© | `quantity Ã— unit_price Ã— (1 - discount_percent/100)` |
| `total_amount` | DÃ©rivÃ© | `SUM(item_total)` par `sale_id` |
| `discount_applied` | Redondant | DÃ©rivable de `discount_percent` |
| `original_price` | Redondant | Existe dÃ©jÃ  dans `products.catalog_price` |

**Justification** : Stocker ces valeurs introduirait des **risques d'incohÃ©rence** 
lors des mises Ã  jour (ex : modification de `quantity` sans recalcul de `item_total`).

#### 5.3 SchÃ©ma relationnel 3FN final

**Tables rÃ©sultantes (3FN)** :
- `customers` : Informations clients
- `products` : Catalogue produits
- `channels` : Canaux de vente
- `campaigns` : Campagnes marketing
- `sales` : Transactions globales (sans `total_amount`)
- `sale_items` : Lignes de vente (sans `item_total`)

#### 5.4 Bilan 3FN

âœ… **Pas de redondance** : Chaque information stockÃ©e une seule fois  
âœ… **Pas de dÃ©pendances transitives** : Attributs dÃ©pendent uniquement des clÃ©s  
âœ… **IntÃ©gritÃ© rÃ©fÃ©rentielle** : Garantie par les clÃ©s Ã©trangÃ¨res  

---

### 6. Normalisation DKNF (Domain-Key Normal Form)

**Objectif** : Garantir que **toutes les contraintes sont exprimÃ©es via des domaines et des clÃ©s**

**Contraintes implÃ©mentÃ©es** :
```sql
-- Contraintes de domaine (CHECK)
ALTER TABLE products
  ADD CONSTRAINT chk_price_positive CHECK (catalog_price > 0);

ALTER TABLE sale_items
  ADD CONSTRAINT chk_quantity_positive CHECK (quantity > 0),
  ADD CONSTRAINT chk_discount_valid CHECK (discount_percent BETWEEN 0 AND 100);

-- Contraintes de clÃ©s (PK + FK + UNIQUE)
ALTER TABLE products
  ADD PRIMARY KEY (product_id),
  ADD UNIQUE (product_name);

ALTER TABLE sale_items
  ADD PRIMARY KEY (item_id),
  ADD FOREIGN KEY (product_id) REFERENCES products(product_id),
  ADD FOREIGN KEY (sale_id) REFERENCES sales(sale_id);
```

**Justification DKNF pour ce projet** :

âœ… **IntÃ©gritÃ© maximale** : Impossible d'insÃ©rer des donnÃ©es invalides (prix nÃ©gatif, quantitÃ© = 0)  
âœ… **Auto-documentation** : Les contraintes SQL documentent les rÃ¨gles mÃ©tier  
âœ… **Performance** : Les index sur FK accÃ©lÃ¨rent les jointures  
âœ… **Maintenance** : Modification du schÃ©ma = modification des contraintes (cohÃ©rence garantie)  

**Pourquoi aller jusqu'Ã  la DKNF dans ce cas ?**

> Dans un contexte e-commerce avec **volumÃ©trie importante** et **intÃ©gritÃ© critique** (transactions financiÃ¨res), la DKNF permet de **dÃ©lÃ©guer la validation mÃ©tier au SGBD** plutÃ´t qu'au code applicatif. Cela Ã©vite les bugs silencieux (ex: vente avec quantitÃ© = -5) et garantit la cohÃ©rence mÃªme en cas d'accÃ¨s multi-applications Ã  la base.

---

### 7. ModÃ¨le Analytique : Star Schema (OLAP)

**ImplÃ©mentation** : Vue SQL pour requÃªtes BI
```sql
CREATE OR REPLACE VIEW vw_sales_star AS
SELECT 
    si.item_id,
    s.sale_date,
    -- Dimension Produit
    p.product_name,
    p.category AS product_category,
    p.catalog_price AS unit_price,
    -- Dimension Client
    c.first_name || ' ' || c.last_name AS customer_name,
    c.country,
    -- MÃ©triques
    si.quantity,
    (si.quantity * si.unit_price) AS revenue
FROM sale_items si
JOIN sales s ON si.sale_id = s.sale_id
JOIN products p ON si.product_id = p.product_id
JOIN customers c ON s.customer_id = c.customer_id;
```

### Diagramme du modÃ¨le logique

**Documentation complÃ¨te avec raisonnement** : [`docs/data_modeling.md`](docs/data_modeling.md)

### Scripts SQL (conformes PostgreSQL)

| Script | Description | CrÃ©ation automatique |
|--------|-------------|----------------------|
| `01_schema.sql` | CrÃ©ation du schÃ©ma `ecommerce` | âœ… Oui (init-db.sh) |
| `02_tables_dknf.sql` | Tables normalisÃ©es DKNF avec PK | âœ… Oui (init-db.sh) |
| `03_views_star_schema.sql` | Vue analytique Star Schema | âœ… Oui (init-db.sh) |
| `04_constraints_indexes.sql` | Contraintes FK, CHECK, index | âœ… Oui (init-db.sh) |

**MÃ©canisme d'initialisation** :
```bash
# Extrait de scripts/init-db.sh
#!/bin/bash
psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" --dbname "$POSTGRES_DB" <<-EOSQL
    \i /sql/01_schema.sql
    \i /sql/02_tables_dknf.sql
    \i /sql/03_views_star_schema.sql
    \i /sql/04_constraints_indexes.sql
EOSQL
```

---

## ğŸš€ Installation et dÃ©marrage

### PrÃ©requis systÃ¨me

- **Docker** â‰¥ 20.10 et **Docker Compose** â‰¥ 2.0
- **Python** â‰¥ 3.12 (pour test local optionnel)
- **Git**
- **8 GB RAM** recommandÃ©s (Airflow + PostgreSQL + MinIO)

### DÃ©marrage complet (recommandÃ©)

**Temps estimÃ©** : ~3 minutes
```bash
# 1. Cloner le repository
git clone <URL_DU_REPO>
cd Projet_artefact

# 2. VÃ©rifier la prÃ©sence du fichier source
ls -l data/source/sales.csv

# 3. Construction de l'image Docker Airflow personnalisÃ©e
docker build -t projet_artefact_airflow:latest -f docker/Dockerfile .

# 4. DÃ©marrer tous les services
docker-compose up -d

# 5. VÃ©rifier la santÃ© des conteneurs
docker-compose ps

# Expected output:
# âœ… postgres_ecommerce  (healthy)
# âœ… minio               (healthy)
# âœ… airflow_db          (healthy)
# âœ… airflow_webserver   (healthy)
# âœ… airflow_scheduler   (Up)
```

### VÃ©rification de l'initialisation
```bash
# 1. VÃ©rifier que les tables DKNF ont Ã©tÃ© crÃ©Ã©es
docker exec -it postgres_ecommerce psql -U ecommerce_user -d ecommerce -c "\dt"

# Expected output:
#  Schema   |      Name       | Type  |     Owner
# ----------+-----------------+-------+----------------
#  public   | customers       | table | ecommerce_user
#  public   | products        | table | ecommerce_user
#  public   | channels        | table | ecommerce_user
#  public   | campaigns       | table | ecommerce_user
#  public   | sales           | table | ecommerce_user
#  public   | sale_items      | table | ecommerce_user

# 2. VÃ©rifier la vue Star Schema
docker exec -it postgres_ecommerce psql -U ecommerce_user -d ecommerce -c "\dv"

# Expected output:
#  Schema   |      Name       | Type |     Owner
# ----------+-----------------+------+----------------
#  public   | vw_sales_star   | view | ecommerce_user

# 3. VÃ©rifier l'upload du fichier dans MinIO
docker exec -it minio mc ls local/folder-source/

# Expected output:
# [2026-02-09 20:00:00 UTC] 1.2MiB sales.csv
```

### Services disponibles

| Service | URL | Identifiants |
|---------|-----|--------------|
| ğŸŒ **Airflow UI** | http://localhost:8081 | `admin` / `admin123` |
| ğŸ“¦ **MinIO Console** | http://localhost:9001 | `minioadmin` / `minioadmin123` |
| ğŸ—„ï¸ **PostgreSQL** | `localhost:5434` | `ecommerce_user` / `ecommerce123` |

---

## ğŸ“– Utilisation

### Option 1 : ExÃ©cution via Airflow (Production)

#### 1. Activer le DAG
```bash
# Via CLI
docker exec -it airflow_webserver airflow dags unpause ingestion_ventes_quotidien

# Ou via l'interface web : http://localhost:8081
# â†’ Toggle ON sur le DAG
```

#### 2. DÃ©clencher une exÃ©cution manuelle
```bash
# IngÃ©rer les donnÃ©es du 15 juin 2025
docker exec -it airflow_webserver airflow dags trigger ingestion_ventes_quotidien
```

#### 3. Monitoring

- **Interface Airflow** : http://localhost:8081/dags/ingestion_ventes_quotidien/grid
- **Logs en temps rÃ©el** :
```bash
  docker logs airflow_scheduler -f
```

#### 4. VÃ©rifier les rÃ©sultats
```bash
docker exec -it postgres_ecommerce psql -U ecommerce_user -d ecommerce

# Dans PostgreSQL
SELECT 
    sale_date,
    COUNT(*) as nb_ventes,
    SUM(quantity) as total_quantity
FROM sale_items si
JOIN sales s ON si.sale_id = s.sale_id
WHERE sale_date = '2025-06-15'
GROUP BY sale_date;
```

### Option 2 : Test rapide sans Airflow

**Cas d'usage** : DÃ©mo rapide pour le recruteur (2 minutes)
```bash
# 1. DÃ©marrer uniquement PostgreSQL + MinIO
docker-compose up -d postgres minio minio_init

# 2. CrÃ©er l'environnement virtuel Python
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Installer les dÃ©pendances (choisir selon le besoin)

## Option A : Installation minimale (pour run_ingestion.py uniquement)
pip install pandas psycopg2-binary boto3 python-dotenv

## Option B : Installation avec requirements-airflow.txt (inclut toutes les deps Airflow)
pip install -r requirements-airflow.txt

## Option C : Installation avec requirements-eda.txt (pour notebooks d'analyse)
pip install -r requirements-eda.txt

# 4. Lancer l'ingestion pour une date spÃ©cifique
python run_ingestion.py

# Le script ingestera les donnÃ©es du 15/06/2025 (DATE_TO_INGEST dÃ©finie dans le script)
```

**ğŸ“‹ Fichiers requirements disponibles** :

| Fichier | Contenu | Usage |
|---------|---------|-------|
| `requirements-airflow.txt` | Apache Airflow + providers + dÃ©pendances ETL | Pour l'image Docker Airflow |
| `requirements-eda.txt` | Jupyter, matplotlib, seaborn, pandas, etc. | Pour l'analyse exploratoire (notebooks) |
| *(aucun requirements.txt de base)* | DÃ©pendances minimales inline | Installation manuelle pour test rapide |

**ğŸ’¡ Recommandation** : Pour un test rapide, privilÃ©giez l'**Option A** (installation manuelle). Pour reproduire l'environnement complet, utilisez `requirements-airflow.txt`.

**Exemple d'exÃ©cution** :
```bash
$ python run_ingestion.py
============================================================
ğŸš€ DÃ©marrage de l'ingestion pour la date 20250615
============================================================
[INFO] Connexion Ã  MinIO...
[INFO] Lecture du fichier sales.csv...
[INFO] Filtrage des donnÃ©es pour la date 2025-06-15...
[INFO] 1247 lignes trouvÃ©es pour cette date
[INFO] Chargement dans PostgreSQL...
[INFO] Insertion dans products: 45 produits
[INFO] Insertion dans customers: 892 clients
[INFO] Insertion dans sale_items: 1247 transactions

============================================================
âœ… Ingestion terminÃ©e avec succÃ¨s pour 20250615
============================================================
```

### RequÃªtes analytiques exemples
```sql
-- Top 5 des produits les plus vendus
SELECT 
    product_name,
    product_category,
    SUM(quantity) as total_sold,
    SUM(revenue) as total_revenue
FROM vw_sales_star
GROUP BY product_name, product_category
ORDER BY total_revenue DESC
LIMIT 5;

-- Ã‰volution mensuelle du CA
SELECT 
    EXTRACT(YEAR FROM sale_date) as year,
    EXTRACT(MONTH FROM sale_date) as month,
    SUM(revenue) as monthly_revenue
FROM vw_sales_star
GROUP BY year, month
ORDER BY year, month;

-- Segmentation clients par pays
SELECT 
    country,
    COUNT(DISTINCT customer_name) as nb_clients,
    SUM(revenue) as ca_total
FROM vw_sales_star
GROUP BY country
ORDER BY ca_total DESC;
```

---

## ğŸ§ª Tests

### StratÃ©gie de test

âœ… **Tests unitaires** : Fonctions utilitaires (`utils.py`)  
âœ… **Tests d'intÃ©gration** : Pipeline complet end-to-end  
âœ… **Tests de robustesse** : Gestion d'erreurs (date invalide, connexion DB)  

### ExÃ©cution des tests
```bash
# 1. Installer pytest
pip install pytest pytest-cov

# 2. Lancer tous les tests
pytest tests/ -v

# Exemple de sortie :
# tests/test_ingestion_utils.py::test_validate_date_format PASSED
# tests/test_ingestion_utils.py::test_transform_customer_data PASSED
# tests/test_ingestion_integration.py::test_full_ingestion_pipeline PASSED
# ======================== 3 passed in 2.45s =========================

# 3. Avec couverture de code
pytest tests/ --cov=ingestion --cov-report=html

# Ouvrir le rapport: htmlcov/index.html
```

### Cas de test implÃ©mentÃ©s

| Test | Fichier | Description |
|------|---------|-------------|
| `test_validate_date_format` | `test_ingestion_utils.py` | Validation format YYYYMMDD |
| `test_extract_from_minio` | `test_ingestion_utils.py` | Connexion et lecture MinIO |
| `test_transform_duplicates` | `test_ingestion_utils.py` | DÃ©doublonnage clients |
| `test_full_pipeline` | `test_ingestion_integration.py` | Ingestion complÃ¨te E2E |
| `test_idempotence` | `test_ingestion_integration.py` | Relance sans duplication |

---

## ğŸ¤” Choix techniques et justifications

### 1. PostgreSQL vs MySQL/MariaDB

**Pourquoi PostgreSQL ?**

âœ… **Contraintes CHECK avancÃ©es** : Validation mÃ©tier au niveau SGBD (DKNF)  
âœ… **Vues matÃ©rialisÃ©es** : Performance sur requÃªtes analytiques  
âœ… **Types personnalisÃ©s** : ENUM pour contraintes mÃ©tier  
âœ… **JSON/JSONB** : FlexibilitÃ© pour Ã©volutions futures  
âœ… **Standard de l'industrie** : UtilisÃ© par Artefact (cf. description du poste)  

**Exemple concret** :
```sql
ALTER TABLE sale_items
  ADD CONSTRAINT chk_discount_valid CHECK (discount_percent BETWEEN 0 AND 100);
```

### 2. MinIO vs S3 direct

**Pourquoi MinIO ?**

âœ… **CompatibilitÃ© API S3** : Code rÃ©utilisable en production AWS/GCP  
âœ… **DÃ©ploiement local** : Pas de compte cloud nÃ©cessaire pour la dÃ©mo  
âœ… **CoÃ»t zÃ©ro** : Open-source et self-hosted  
âœ… **Interface web** : Visualisation des buckets (pratique pour le recruteur)  

### 3. Airflow 3.x : TaskFlow API vs Operators classiques

**Choix : TaskFlow API avec `@task` decorator**

âœ… **LisibilitÃ©** : Code plus Pythonic et concis  
âœ… **Type hints** : Meilleure auto-complÃ©tion IDE  
âœ… **Gestion XCom automatique** : Pas de `ti.xcom_push/pull` manuel  
âœ… **Recommandation officielle** : Best practice Airflow 3.x  

**Exemple** :
```python
@task
def run_ingestion(**context):
    date_str = context['ds_nodash']
    ingest_sales(date_str)
```

### 4. Idempotence : UPSERT vs DELETE + INSERT

**Choix : UPSERT avec `ON CONFLICT DO UPDATE`**

âœ… **AtomicitÃ©** : Une seule transaction  
âœ… **Performance** : Pas de DELETE/INSERT coÃ»teux  
âœ… **SÃ©curitÃ©** : Pas de perte de donnÃ©es en cas d'Ã©chec  

**ImplÃ©mentation** :
```python
INSERT INTO products (product_id, product_name, category, catalog_price)
VALUES (%s, %s, %s, %s)
ON CONFLICT (product_id) DO UPDATE SET
    product_name = EXCLUDED.product_name,
    catalog_price = EXCLUDED.catalog_price;
```

### 5. Logging : print() vs logging module

**Choix : Module `logging` Python**

âœ… **Niveaux de log** : INFO, WARNING, ERROR  
âœ… **Format standardisÃ©** : Timestamp, niveau, message  
âœ… **IntÃ©gration Airflow** : Logs visibles dans l'UI  

**Configuration** :
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)
logger.info("DÃ©but de l'ingestion pour la date %s", date_str)
```

### 6. 3FN vs DKNF : Pourquoi aller plus loin ?

**Contexte e-commerce** :

| Risque sans DKNF | Impact | Solution DKNF |
|------------------|--------|---------------|
| Prix nÃ©gatif | Perte financiÃ¨re | `CHECK (price > 0)` |
| QuantitÃ© = 0 | Commande fantÃ´me | `CHECK (quantity > 0)` |
| Remise > 100% | IncohÃ©rence comptable | `CHECK (discount_percent BETWEEN 0 AND 100)` |

**Conclusion** : Dans un contexte avec **intÃ©gritÃ© critique** (transactions financiÃ¨res), la DKNF dÃ©place la validation du code vers le SGBD â†’ **garantie absolue** mÃªme en cas d'accÃ¨s direct SQL.

### 7. Docker Compose : services sÃ©parÃ©s vs monolithique

**Choix : Architecture microservices**

âœ… **Isolation** : RedÃ©marrage d'un service n'affecte pas les autres  
âœ… **ScalabilitÃ©** : Ajout facile de workers Airflow  
âœ… **Debugging** : Logs sÃ©parÃ©s par service  
âœ… **Production-ready** : Pattern standard Kubernetes  

---

## ğŸ“ Structure du projet
```
Projet_artefact/
â”‚
â”œâ”€â”€ ğŸ“‚ data/                      # DonnÃ©es sources
â”‚   â””â”€â”€ source/
â”‚       â””â”€â”€ sales.csv             # â­ Fichier fourni par Artefact
â”‚
â”œâ”€â”€ ğŸ“‚ docker/                    # Configurations Docker
â”‚   â””â”€â”€ Dockerfile.airflow        # Image custom Airflow 3.x
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                      # ğŸ“„ Documentation complÃ¨te
â”‚   â”œâ”€â”€ data_model/
â”‚   â”‚   â”œâ”€â”€ logical_data_model.png       # Diagramme ERD
â”‚   â”‚   â””â”€â”€ logical_data_model.drawio    # Source Ã©ditable
â”‚   â”œâ”€â”€ analysis_exploratoire/
â”‚   â”‚   â””â”€â”€ EDA_sales.ipynb              # â­ Notebook Jupyter
â”‚   â””â”€â”€ data_modeling.md                 # â­ Raisonnement de modÃ©lisation
â”‚
â”œâ”€â”€ ğŸ“‚ ingestion/                 # ğŸ Module Python ETL
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                 # Configuration (env vars)
â”‚   â”œâ”€â”€ main.py                   # â­ Pipeline principal
â”‚   â””â”€â”€ utils.py                  # Fonctions utilitaires
â”‚
â”œâ”€â”€ ğŸ“‚ airflow/                   # Airflow DAGs & config
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ dag_ingestion.py      # â­ DAG quotidien
â”‚   â”œâ”€â”€ logs/                     # Logs d'exÃ©cution
â”‚   â””â”€â”€ plugins/                  # Custom operators
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                   # Scripts d'initialisation
â”‚   â””â”€â”€ init-db.sh                # â­ Auto-crÃ©ation tables DKNF
â”‚
â”œâ”€â”€ ğŸ“‚ sql/                       # ğŸ“œ Scripts SQL (PostgreSQL)
â”‚   â”œâ”€â”€ 01_schema.sql             # SchÃ©ma
â”‚   â”œâ”€â”€ 02_tables_dknf.sql        # â­ Tables normalisÃ©es DKNF
â”‚   â”œâ”€â”€ 03_views_star_schema.sql  # â­ Vue analytique
â”‚   â””â”€â”€ 04_constraints_indexes.sql # â­ Contraintes FK + index
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                     # ğŸ§ª Tests automatisÃ©s
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_ingestion_integration.py  # Tests E2E
â”‚   â””â”€â”€ test_ingestion_utils.py        # Tests unitaires
â”‚
â”œâ”€â”€ ğŸ³ docker-compose.yml         # â­ Orchestration complÃ¨te
â”œâ”€â”€ ğŸ“‹ requirements-airflow.txt   # â­ DÃ©pendances Airflow + ETL
â”œâ”€â”€ ğŸ“‹ requirements-eda.txt       # â­ DÃ©pendances analyse exploratoire
â”œâ”€â”€ ğŸ run_ingestion.py           # â­ Script de test rapide
â”œâ”€â”€ âš™ï¸ pytest.ini                 # Configuration tests
â””â”€â”€ ğŸ“– README.md                  # â­ Ce fichier
```

**LÃ©gende** :
- â­ = Fichiers critiques pour l'Ã©valuation
- ğŸ“‚ = Dossiers structurants
- ğŸ = Code Python
- ğŸ“œ = Scripts SQL
- ğŸ³ = Infrastructure Docker

---

## ğŸ“š Documentation

### 1. Analyse exploratoire

**Fichier** : [`docs/analysis_exploratoire.ipynb`](docs/analysis_exploratoire.ipynb)

**Contenu** :
- âœ… Statistiques descriptives (cardinalitÃ©, missing values)
- âœ… Distribution des ventes par catÃ©gorie
- âœ… Analyse temporelle (saisonnalitÃ©, tendances)
- âœ… DÃ©tection d'anomalies (outliers, doublons)
- âœ… Identification des entitÃ©s mÃ©tier

### 2. ModÃ©lisation des donnÃ©es

**Fichier** : [`docs/data_modeling.md`](docs/data_modeling.md)

**Contenu** :
- âœ… **Raisonnement complet** : De l'EDA jusqu'Ã  la DKNF
- âœ… DÃ©marche de normalisation 1FN â†’ 2FN â†’ 3FN â†’ DKNF
- âœ… Diagramme ERD (EntitÃ©-Relation)
- âœ… Justification de chaque choix de modÃ©lisation
- âœ… Dictionnaire de donnÃ©es (types, contraintes)
- âœ… StratÃ©gie de sÃ©paration OLTP (3FN) / OLAP (Star Schema)

### 3. API Airflow : Connexions et Variables

**Connexions configurÃ©es** (via environment variables) :
```yaml
# Dans docker-compose.yml
AIRFLOW_CONN_POSTGRES_ECOMMERCE: postgresql://ecommerce_user:ecommerce123@postgres:5432/ecommerce
AIRFLOW_CONN_MINIO_S3: aws://minioadmin:minioadmin123@?endpoint_url=http://minio:9000
```

**Variables configurÃ©es** :
```yaml
AIRFLOW_VAR_MINIO_BUCKET: folder-source
AIRFLOW_VAR_SOURCE_FILE: sales.csv
```

### 4. Gestion des dÃ©pendances

**Fichiers requirements** :
```txt
requirements-airflow.txt    # UtilisÃ© par Dockerfile.airflow
requirements-eda.txt        # UtilisÃ© pour les notebooks Jupyter
```

**Structure modulaire** :
- âœ… `requirements-airflow.txt` : Apache Airflow + providers PostgreSQL/Amazon + pandas + psycopg2-binary + boto3
- âœ… `requirements-eda.txt` : jupyter + matplotlib + seaborn + plotly + pandas

**Justification** : SÃ©paration des environnements pour Ã©viter les conflits de versions et optimiser les images Docker.

---

## ğŸ› ï¸ Troubleshooting

### ProblÃ¨me : Tables DKNF non crÃ©Ã©es au dÃ©marrage

**SymptÃ´me** :
```bash
$ docker exec -it postgres_ecommerce psql -U ecommerce_user -d ecommerce -c "\dt"
Did not find any relations.
```

**Solution** :
```bash
# VÃ©rifier les logs d'initialisation
docker logs postgres_ecommerce | grep "sql"

# Relancer l'initialisation manuellement
docker exec -it postgres_ecommerce bash -c "
  psql -U ecommerce_user -d ecommerce < /sql/01_schema.sql &&
  psql -U ecommerce_user -d ecommerce < /sql/02_tables_dknf.sql &&
  psql -U ecommerce_user -d ecommerce < /sql/03_views_star_schema.sql &&
  psql -U ecommerce_user -d ecommerce < /sql/04_constraints_indexes.sql
"
```

### ProblÃ¨me : Airflow ne voit pas le DAG

**Solution** :
```bash
# Forcer le rechargement
docker exec -it airflow_scheduler airflow dags reserialize

# VÃ©rifier les erreurs d'import
docker exec -it airflow_webserver airflow dags list-import-errors
```

### ProblÃ¨me : Fichier sales.csv non uploadÃ© dans MinIO

**Solution** :
```bash
# Relancer le service d'initialisation MinIO
docker-compose up -d minio_init

# VÃ©rifier les logs
docker logs minio_init
```

---

## ğŸ‘¤ Auteur

**Adele Coulibaly**  
Candidat Stagiaire Data Engineer - Artefact CI  
ğŸ“§ adele@artefact.ci

---

